{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1187720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b4\n",
    "from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0632034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "#check version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a046c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sites: 148\n"
     ]
    }
   ],
   "source": [
    "PATH_FEAT_TRAIN = 'train_features.csv'\n",
    "PATH_LABEL_TRAIN = 'train_labels.csv'\n",
    "RANDOM_SEED = 33\n",
    "# Load the CSV dataset into a Pandas DataFrame\n",
    "df_feat = pd.read_csv(PATH_FEAT_TRAIN)\n",
    "df_label = pd.read_csv(PATH_LABEL_TRAIN)\n",
    "# Get unique site values from the dataset\n",
    "unique_sites = df_feat['site'].unique()\n",
    "print(f'Number of sites: {len(unique_sites)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a1bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting successful.\n"
     ]
    }
   ],
   "source": [
    "# Extract the one-hot encoded labels as a NumPy array\n",
    "labels_one_hot = df_label.iloc[:, 1:].values\n",
    "# Convert one-hot encoded labels to numerical labels\n",
    "labels_numeric = np.argmax(labels_one_hot, axis=1)\n",
    "# Add the numerical labels to the DataFrame\n",
    "df_feat['label'] = labels_numeric\n",
    "\n",
    "# Split the unique sites into training and val sets\n",
    "train_sites, val_sites = train_test_split(unique_sites, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Split the dataset based on the selected site values\n",
    "train = df_feat[df_feat['site'].isin(train_sites)]\n",
    "val = df_feat[df_feat['site'].isin(val_sites)]\n",
    "\n",
    "# Verify that the 'site' feature is disjoint between the two splits\n",
    "common_sites = set(train['site']).intersection(set(val['site']))\n",
    "if len(common_sites) > 0:\n",
    "    print(\"Error: The 'site' feature is not disjoint between the splits.\")\n",
    "else:\n",
    "    print(\"Splitting successful.\")\n",
    "\n",
    "# Save the training and val sets to separate CSV files\n",
    "train.to_csv('train.csv', index=False)\n",
    "val.to_csv('val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ccef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 1, ..., 3, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1240ec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2474\n",
      "1: 1641\n",
      "2: 2213\n",
      "3: 2423\n",
      "4: 978\n",
      "5: 2254\n",
      "6: 2492\n",
      "7: 2013\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(labels_numeric, return_counts=True)\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58b230b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    653\n",
       "6    474\n",
       "3    388\n",
       "7    339\n",
       "2    332\n",
       "1    263\n",
       "4    155\n",
       "5    148\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037b8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire train feat with numerical labels to CSV file\n",
    "df_feat.to_csv('train_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b3cecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successFolder already exists!\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "folder_path = os.path.join(current_dir, \"weights\")\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(\"Folder has been created successfully!\")\n",
    "else:\n",
    "    print(\"successFolder already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af2f795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successFolder already exists!\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "folder_path = os.path.join(current_dir, \"submissions\")\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(\"Folder has been created successfully!\")\n",
    "else:\n",
    "    print(\"successFolder already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb34c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for CPU\n",
    "torch.manual_seed(33)\n",
    "random.seed(33)\n",
    "np.random.seed(33)\n",
    "\n",
    "# Set random seeds for GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(33)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f41dcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2061/2061 [09:12<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.34959\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2061/2061 [09:09<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.82591\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2061/2061 [09:09<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.63420\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2061/2061 [09:24<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.52254\n",
      "Weights saved to weights/efficientnet_b4_final.pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your CSV file\n",
    "PATH_CSV_TRAIN = 'train_all.csv'\n",
    "DIR_IMG = './'\n",
    "NB_EPOCHS = 4\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "\n",
    "# Define the image transformation pipeline for training data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((366, 366)),  # Resize the input image\n",
    "    transforms.RandomCrop((320, 320)),  # Randomly crop the image\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.4, saturation=0.4, hue=0.1),  # Adjust brightness, contrast, saturation, and hue\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "\n",
    "# Create a custom dataset class\n",
    "class CSV_Dataset(Dataset):\n",
    "    def __init__(self, path_csv_file, transform=None):\n",
    "        self.data = pd.read_csv(path_csv_file)\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(list(self.data['label'].unique()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(DIR_IMG,self.data.iloc[idx]['filepath'])\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create an instance of the custom dataset for training\n",
    "train_dataset = CSV_Dataset(PATH_CSV_TRAIN, transform=train_transform)\n",
    "\n",
    "# Create data loaders for training sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "# Load the pre-trained ResNet model\n",
    "model = efficientnet_b4(weights=EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "#print(model.classifier)\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "\n",
    "# Replace the last fully connected layer with a new one suitable for the number of classes\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features=num_ftrs, out_features=num_classes)\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f'Train loss: {train_loss:.5f}') \n",
    "\n",
    "\n",
    "\n",
    "path_weights = f'weights/efficientnet_b4_final.pth'\n",
    "torch.save(model.state_dict(), path_weights)\n",
    "print(f\"Weights saved to {path_weights}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4334fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1031/1031 [07:36<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.14306\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1031/1031 [07:35<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.61587\n",
      "Weights saved to weights/efficientnet_v2_s_final.pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your CSV file\n",
    "PATH_CSV_TRAIN = 'train_all.csv'\n",
    "DIR_IMG = './'\n",
    "NB_EPOCHS = 2\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "# Define the image transformation pipeline for training data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((366, 366)),  # Resize the input image\n",
    "    transforms.RandomCrop((320, 320)),  # Randomly crop the image\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.4, saturation=0.4, hue=0.1),  # Adjust brightness, contrast, saturation, and hue\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "\n",
    "# Create a custom dataset class\n",
    "class CSV_Dataset(Dataset):\n",
    "    def __init__(self, path_csv_file, transform=None):\n",
    "        self.data = pd.read_csv(path_csv_file)\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(list(self.data['label'].unique()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(DIR_IMG,self.data.iloc[idx]['filepath'])\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create an instance of the custom dataset for training\n",
    "train_dataset = CSV_Dataset(PATH_CSV_TRAIN, transform=train_transform)\n",
    "\n",
    "\n",
    "# Create data loaders for training and sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "# Load the pre-trained ResNet model\n",
    "model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "\n",
    "# Replace the last fully connected layer with a new one suitable for the number of classes\n",
    "num_ftrs = model.classifier[1].in_features # EfficientNet\n",
    "model.classifier[1] = nn.Linear(in_features=num_ftrs, out_features=num_classes) # EfficientNet\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Create a cosine annealing scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f'Train loss: {train_loss:.5f}') \n",
    "\n",
    "\n",
    "path_weights = f'weights/efficientnet_v2_s_final.pth'\n",
    "torch.save(model.state_dict(), path_weights)\n",
    "print(f\"Weights saved to {path_weights}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c168bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [01:34<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_CSV_VAL = 'test_features.csv'\n",
    "DIR_IMG = './'\n",
    "BATCH_SIZE = 64\n",
    "PATH_WEIGHTS = 'weights/efficientnet_b4_final.pth'\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),  # Resize the input image\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Create a custom dataset class\n",
    "class CSV_Dataset(Dataset):\n",
    "    def __init__(self, path_csv_file, transform=None):\n",
    "        self.data = pd.read_csv(path_csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(DIR_IMG,self.data.iloc[idx]['filepath'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "    \n",
    "val_dataset = CSV_Dataset(PATH_CSV_VAL, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Load the pre-trained ResNet model\n",
    "model = efficientnet_b4(weights=None)\n",
    "num_classes = 8\n",
    "\n",
    "# Replace the last fully connected layer with a new one suitable for the number of classes\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features=num_ftrs, out_features=num_classes)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH_WEIGHTS))\n",
    "# Validation loop\n",
    "model.eval()\n",
    "\n",
    "list_labels = []\n",
    "list_logits = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(val_loader):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        list_logits.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "arr_logits = np.concatenate(list_logits, axis=0)\n",
    "probabilities = np.exp(arr_logits) / np.sum(np.exp(arr_logits), axis=1, keepdims=True)\n",
    "\n",
    "# Specify the file path and name\n",
    "file_path = \"predictions_efficientnet_b4_final.csv\"\n",
    "\n",
    "\n",
    "# Save the NumPy array as CSV\n",
    "np.savetxt(file_path, probabilities, delimiter=\",\", fmt=\"%.18f\",\n",
    "           header=\"antelope_duiker,bird,blank,civet_genet,hog,leopard,monkey_prosimian,rodent\", comments=\"\")\n",
    "\n",
    "print(\"CSV file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b99eea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [01:02<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_CSV_VAL = 'test_features.csv'\n",
    "DIR_IMG = './'\n",
    "BATCH_SIZE = 64\n",
    "PATH_WEIGHTS = 'weights/efficientnet_v2_s_final.pth'\n",
    "\n",
    "# Create a custom dataset class\n",
    "class CSV_Dataset(Dataset):\n",
    "    def __init__(self, path_csv_file, transform=None):\n",
    "        self.data = pd.read_csv(path_csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(DIR_IMG, self.data.iloc[idx]['filepath'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Assuming you have already defined your val_transform\n",
    "val_dataset = CSV_Dataset(PATH_CSV_VAL, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Load the pre-trained ResNet model\n",
    "model = efficientnet_v2_s(weights=None)\n",
    "num_classes = 8\n",
    "\n",
    "# Replace the last fully connected layer with a new one suitable for the number of classes\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features=num_ftrs, out_features=num_classes)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH_WEIGHTS))\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "\n",
    "list_labels = []\n",
    "list_logits = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(val_loader):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        list_logits.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "arr_logits = np.concatenate(list_logits, axis=0)\n",
    "\n",
    "# Calculate stable probabilities using the Log-Sum-Exp trick\n",
    "max_logits = np.max(arr_logits, axis=1, keepdims=True)\n",
    "exp_logits = np.exp(arr_logits - max_logits)\n",
    "sum_exp_logits = np.sum(exp_logits, axis=1, keepdims=True)\n",
    "probabilities = exp_logits / sum_exp_logits\n",
    "\n",
    "# Specify the file path and name\n",
    "file_path = \"predictions_efficientnet_v2_s_final.csv\"\n",
    "\n",
    "# Save the probabilities as a CSV file\n",
    "column_names = \"antelope_duiker,bird,blank,civet_genet,hog,leopard,monkey_prosimian,rodent\"\n",
    "np.savetxt(file_path, probabilities, delimiter=\",\", fmt=\"%.18f\", header=column_names, comments=\"\")\n",
    "\n",
    "print(\"CSV file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7f30494",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FEAT_TEST = 'test_features.csv'\n",
    "PATH_PRED_TEST = 'predictions_efficientnet_v2_s_final.csv'\n",
    "\n",
    "# Load the CSVs into a Pandas DataFrames\n",
    "df_feat_test = pd.read_csv(PATH_FEAT_TEST)\n",
    "df_pred_test = pd.read_csv(PATH_PRED_TEST)\n",
    "\n",
    "df_concatenated = pd.concat([df_feat_test['id'], df_pred_test], axis=1)\n",
    "\n",
    "# Save the predictions with 'id' as final submission\n",
    "df_concatenated.to_csv('submissions/submission_efficientnet_v2_s.csv', index=False, float_format='%.17f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7c001c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PRED_TEST_1 = 'predictions_efficientnet_b4_final.csv'\n",
    "PATH_PRED_TEST_2 = 'predictions_efficientnet_v2_s_final.csv'\n",
    "\n",
    "df_pred_test_1 = pd.read_csv(PATH_PRED_TEST_1)\n",
    "df_pred_test_2 = pd.read_csv(PATH_PRED_TEST_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e4fc401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antelope_duiker</th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>civet_genet</th>\n",
       "      <th>hog</th>\n",
       "      <th>leopard</th>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <th>rodent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117568</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.466066</td>\n",
       "      <td>0.146908</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.219343</td>\n",
       "      <td>0.017075</td>\n",
       "      <td>0.029557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759322</td>\n",
       "      <td>0.075972</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.007243</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.051998</td>\n",
       "      <td>0.060973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.874866</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.021595</td>\n",
       "      <td>0.037271</td>\n",
       "      <td>0.046623</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.012677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.993830</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400713</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.438032</td>\n",
       "      <td>0.049031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>0.558863</td>\n",
       "      <td>0.146085</td>\n",
       "      <td>0.223677</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>0.318218</td>\n",
       "      <td>0.064048</td>\n",
       "      <td>0.257517</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.027992</td>\n",
       "      <td>0.044985</td>\n",
       "      <td>0.252139</td>\n",
       "      <td>0.032563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0.352891</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.093526</td>\n",
       "      <td>0.066368</td>\n",
       "      <td>0.448201</td>\n",
       "      <td>0.025855</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.006058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>0.926172</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.018517</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.009560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>0.026387</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.052815</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.898911</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      antelope_duiker      bird     blank  civet_genet       hog   leopard  \\\n",
       "0            0.117568  0.002528  0.466066     0.146908  0.000955  0.219343   \n",
       "1            0.759322  0.075972  0.036527     0.007461  0.007243  0.000504   \n",
       "2            0.874866  0.000366  0.021595     0.037271  0.046623  0.000540   \n",
       "3            0.000713  0.000050  0.003030     0.000559  0.000292  0.993830   \n",
       "4            0.400713  0.058642  0.043021     0.004127  0.004579  0.001855   \n",
       "...               ...       ...       ...          ...       ...       ...   \n",
       "4459         0.558863  0.146085  0.223677     0.000037  0.012209  0.016060   \n",
       "4460         0.318218  0.064048  0.257517     0.002539  0.027992  0.044985   \n",
       "4461         0.352891  0.002252  0.093526     0.066368  0.448201  0.025855   \n",
       "4462         0.926172  0.008151  0.018517     0.000073  0.008509  0.000557   \n",
       "4463         0.026387  0.000477  0.052815     0.000123  0.000500  0.898911   \n",
       "\n",
       "      monkey_prosimian    rodent  \n",
       "0             0.017075  0.029557  \n",
       "1             0.051998  0.060973  \n",
       "2             0.006062  0.012677  \n",
       "3             0.000468  0.001058  \n",
       "4             0.438032  0.049031  \n",
       "...                ...       ...  \n",
       "4459          0.041616  0.001452  \n",
       "4460          0.252139  0.032563  \n",
       "4461          0.004847  0.006058  \n",
       "4462          0.028460  0.009560  \n",
       "4463          0.020245  0.000542  \n",
       "\n",
       "[4464 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c119bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antelope_duiker</th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>civet_genet</th>\n",
       "      <th>hog</th>\n",
       "      <th>leopard</th>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <th>rodent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040666</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>0.336740</td>\n",
       "      <td>0.326252</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.028478</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.245251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.774848</td>\n",
       "      <td>0.061645</td>\n",
       "      <td>0.043821</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.036770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.370690</td>\n",
       "      <td>0.027518</td>\n",
       "      <td>0.041680</td>\n",
       "      <td>0.387572</td>\n",
       "      <td>0.093348</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.063754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.983364</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029922</td>\n",
       "      <td>0.026674</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.081906</td>\n",
       "      <td>0.838013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>0.204061</td>\n",
       "      <td>0.119244</td>\n",
       "      <td>0.644718</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.028066</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>0.139765</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0.433451</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.386466</td>\n",
       "      <td>0.011446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.658301</td>\n",
       "      <td>0.017711</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.131687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>0.745738</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.065390</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0.010384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.990235</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      antelope_duiker      bird     blank  civet_genet       hog   leopard  \\\n",
       "0            0.040666  0.016382  0.336740     0.326252  0.004045  0.028478   \n",
       "1            0.774848  0.061645  0.043821     0.005129  0.031801  0.002347   \n",
       "2            0.370690  0.027518  0.041680     0.387572  0.093348  0.002761   \n",
       "3            0.001153  0.004407  0.004163     0.001578  0.002299  0.983364   \n",
       "4            0.029922  0.026674  0.009233     0.011672  0.001128  0.001452   \n",
       "...               ...       ...       ...          ...       ...       ...   \n",
       "4459         0.204061  0.119244  0.644718     0.000042  0.001436  0.001914   \n",
       "4460         0.139765  0.015247  0.433451     0.000426  0.005509  0.007690   \n",
       "4461         0.092884  0.005351  0.658301     0.017711  0.079508  0.011476   \n",
       "4462         0.745738  0.014403  0.012940     0.000702  0.065390  0.003111   \n",
       "4463         0.000797  0.001245  0.005916     0.000327  0.000335  0.990235   \n",
       "\n",
       "      monkey_prosimian    rodent  \n",
       "0             0.002185  0.245251  \n",
       "1             0.043639  0.036770  \n",
       "2             0.012677  0.063754  \n",
       "3             0.001959  0.001079  \n",
       "4             0.081906  0.838013  \n",
       "...                ...       ...  \n",
       "4459          0.028066  0.000520  \n",
       "4460          0.386466  0.011446  \n",
       "4461          0.003082  0.131687  \n",
       "4462          0.147333  0.010384  \n",
       "4463          0.000615  0.000531  \n",
       "\n",
       "[4464 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6474a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test_2 = df_pred_test_2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c4ca261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antelope_duiker</th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>civet_genet</th>\n",
       "      <th>hog</th>\n",
       "      <th>leopard</th>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <th>rodent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040666</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>0.336740</td>\n",
       "      <td>0.326252</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.028478</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.245251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.774848</td>\n",
       "      <td>0.061645</td>\n",
       "      <td>0.043821</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.036770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.370690</td>\n",
       "      <td>0.027518</td>\n",
       "      <td>0.041680</td>\n",
       "      <td>0.387572</td>\n",
       "      <td>0.093348</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.063754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.983364</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029922</td>\n",
       "      <td>0.026674</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.081906</td>\n",
       "      <td>0.838013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>0.204061</td>\n",
       "      <td>0.119244</td>\n",
       "      <td>0.644718</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.028066</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>0.139765</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0.433451</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.386466</td>\n",
       "      <td>0.011446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.658301</td>\n",
       "      <td>0.017711</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.131687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>0.745738</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.065390</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0.010384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.990235</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      antelope_duiker      bird     blank  civet_genet       hog   leopard  \\\n",
       "0            0.040666  0.016382  0.336740     0.326252  0.004045  0.028478   \n",
       "1            0.774848  0.061645  0.043821     0.005129  0.031801  0.002347   \n",
       "2            0.370690  0.027518  0.041680     0.387572  0.093348  0.002761   \n",
       "3            0.001153  0.004407  0.004163     0.001578  0.002299  0.983364   \n",
       "4            0.029922  0.026674  0.009233     0.011672  0.001128  0.001452   \n",
       "...               ...       ...       ...          ...       ...       ...   \n",
       "4459         0.204061  0.119244  0.644718     0.000042  0.001436  0.001914   \n",
       "4460         0.139765  0.015247  0.433451     0.000426  0.005509  0.007690   \n",
       "4461         0.092884  0.005351  0.658301     0.017711  0.079508  0.011476   \n",
       "4462         0.745738  0.014403  0.012940     0.000702  0.065390  0.003111   \n",
       "4463         0.000797  0.001245  0.005916     0.000327  0.000335  0.990235   \n",
       "\n",
       "      monkey_prosimian    rodent  \n",
       "0             0.002185  0.245251  \n",
       "1             0.043639  0.036770  \n",
       "2             0.012677  0.063754  \n",
       "3             0.001959  0.001079  \n",
       "4             0.081906  0.838013  \n",
       "...                ...       ...  \n",
       "4459          0.028066  0.000520  \n",
       "4460          0.386466  0.011446  \n",
       "4461          0.003082  0.131687  \n",
       "4462          0.147333  0.010384  \n",
       "4463          0.000615  0.000531  \n",
       "\n",
       "[4464 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4a4b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (df_pred_test_1 + df_pred_test_2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06171f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antelope_duiker</th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>civet_genet</th>\n",
       "      <th>hog</th>\n",
       "      <th>leopard</th>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <th>rodent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079117</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.401403</td>\n",
       "      <td>0.236580</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.123911</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.137404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767085</td>\n",
       "      <td>0.068808</td>\n",
       "      <td>0.040174</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.019522</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.047818</td>\n",
       "      <td>0.048872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.622778</td>\n",
       "      <td>0.013942</td>\n",
       "      <td>0.031638</td>\n",
       "      <td>0.212422</td>\n",
       "      <td>0.069986</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>0.038215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.988597</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.215317</td>\n",
       "      <td>0.042658</td>\n",
       "      <td>0.026127</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.259969</td>\n",
       "      <td>0.443522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>0.381462</td>\n",
       "      <td>0.132665</td>\n",
       "      <td>0.434197</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.034841</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>0.228992</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.345484</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.016751</td>\n",
       "      <td>0.026337</td>\n",
       "      <td>0.319303</td>\n",
       "      <td>0.022004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0.222888</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.375914</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.263855</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.068872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.036949</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.087896</td>\n",
       "      <td>0.009972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>0.013592</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.029366</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.944573</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      antelope_duiker      bird     blank  civet_genet       hog   leopard  \\\n",
       "0            0.079117  0.009455  0.401403     0.236580  0.002500  0.123911   \n",
       "1            0.767085  0.068808  0.040174     0.006295  0.019522  0.001426   \n",
       "2            0.622778  0.013942  0.031638     0.212422  0.069986  0.001650   \n",
       "3            0.000933  0.002228  0.003597     0.001069  0.001295  0.988597   \n",
       "4            0.215317  0.042658  0.026127     0.007899  0.002854  0.001654   \n",
       "...               ...       ...       ...          ...       ...       ...   \n",
       "4459         0.381462  0.132665  0.434197     0.000039  0.006823  0.008987   \n",
       "4460         0.228992  0.039647  0.345484     0.001482  0.016751  0.026337   \n",
       "4461         0.222888  0.003802  0.375914     0.042040  0.263855  0.018666   \n",
       "4462         0.835955  0.011277  0.015729     0.000387  0.036949  0.001834   \n",
       "4463         0.013592  0.000861  0.029366     0.000225  0.000418  0.944573   \n",
       "\n",
       "      monkey_prosimian    rodent  \n",
       "0             0.009630  0.137404  \n",
       "1             0.047818  0.048872  \n",
       "2             0.009370  0.038215  \n",
       "3             0.001213  0.001068  \n",
       "4             0.259969  0.443522  \n",
       "...                ...       ...  \n",
       "4459          0.034841  0.000986  \n",
       "4460          0.319303  0.022004  \n",
       "4461          0.003964  0.068872  \n",
       "4462          0.087896  0.009972  \n",
       "4463          0.010430  0.000536  \n",
       "\n",
       "[4464 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "848eb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('predictions_ensemble_1.csv', index=False, float_format='%.17f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ada5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([df_feat_test['id'], result], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af769e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>antelope_duiker</th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>civet_genet</th>\n",
       "      <th>hog</th>\n",
       "      <th>leopard</th>\n",
       "      <th>monkey_prosimian</th>\n",
       "      <th>rodent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZJ016488</td>\n",
       "      <td>0.079117</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.401403</td>\n",
       "      <td>0.236580</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.123911</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.137404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZJ016489</td>\n",
       "      <td>0.767085</td>\n",
       "      <td>0.068808</td>\n",
       "      <td>0.040174</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.019522</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.047818</td>\n",
       "      <td>0.048872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZJ016490</td>\n",
       "      <td>0.622778</td>\n",
       "      <td>0.013942</td>\n",
       "      <td>0.031638</td>\n",
       "      <td>0.212422</td>\n",
       "      <td>0.069986</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>0.038215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZJ016491</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.988597</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZJ016492</td>\n",
       "      <td>0.215317</td>\n",
       "      <td>0.042658</td>\n",
       "      <td>0.026127</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.259969</td>\n",
       "      <td>0.443522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>ZJ020947</td>\n",
       "      <td>0.381462</td>\n",
       "      <td>0.132665</td>\n",
       "      <td>0.434197</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.034841</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>ZJ020948</td>\n",
       "      <td>0.228992</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.345484</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.016751</td>\n",
       "      <td>0.026337</td>\n",
       "      <td>0.319303</td>\n",
       "      <td>0.022004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>ZJ020949</td>\n",
       "      <td>0.222888</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.375914</td>\n",
       "      <td>0.042040</td>\n",
       "      <td>0.263855</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.068872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>ZJ020950</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.036949</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.087896</td>\n",
       "      <td>0.009972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>ZJ020951</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.029366</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.944573</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  antelope_duiker      bird     blank  civet_genet       hog  \\\n",
       "0     ZJ016488         0.079117  0.009455  0.401403     0.236580  0.002500   \n",
       "1     ZJ016489         0.767085  0.068808  0.040174     0.006295  0.019522   \n",
       "2     ZJ016490         0.622778  0.013942  0.031638     0.212422  0.069986   \n",
       "3     ZJ016491         0.000933  0.002228  0.003597     0.001069  0.001295   \n",
       "4     ZJ016492         0.215317  0.042658  0.026127     0.007899  0.002854   \n",
       "...        ...              ...       ...       ...          ...       ...   \n",
       "4459  ZJ020947         0.381462  0.132665  0.434197     0.000039  0.006823   \n",
       "4460  ZJ020948         0.228992  0.039647  0.345484     0.001482  0.016751   \n",
       "4461  ZJ020949         0.222888  0.003802  0.375914     0.042040  0.263855   \n",
       "4462  ZJ020950         0.835955  0.011277  0.015729     0.000387  0.036949   \n",
       "4463  ZJ020951         0.013592  0.000861  0.029366     0.000225  0.000418   \n",
       "\n",
       "       leopard  monkey_prosimian    rodent  \n",
       "0     0.123911          0.009630  0.137404  \n",
       "1     0.001426          0.047818  0.048872  \n",
       "2     0.001650          0.009370  0.038215  \n",
       "3     0.988597          0.001213  0.001068  \n",
       "4     0.001654          0.259969  0.443522  \n",
       "...        ...               ...       ...  \n",
       "4459  0.008987          0.034841  0.000986  \n",
       "4460  0.026337          0.319303  0.022004  \n",
       "4461  0.018666          0.003964  0.068872  \n",
       "4462  0.001834          0.087896  0.009972  \n",
       "4463  0.944573          0.010430  0.000536  \n",
       "\n",
       "[4464 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "621e41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated.to_csv('submissions/submission_ensemble_v1.csv', index=False, float_format='%.17f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0416a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
